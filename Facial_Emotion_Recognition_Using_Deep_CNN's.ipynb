{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial Emotion Recognition Using Deep CNN's",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxQDaDGyjcYP",
        "colab_type": "text"
      },
      "source": [
        "# Facial Emotion Recognition \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQpjWg4Ld6m",
        "colab_type": "text"
      },
      "source": [
        "##  Connect google Drive.\n",
        "\n",
        "FER2013 dataset.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyTEuhg7fR9P",
        "colab_type": "code",
        "outputId": "8929210a-4cbf-44ad-9483-7dfee3f1dbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRPQRtXGmm2W",
        "colab_type": "code",
        "outputId": "0c15ac79-03c6-4455-f150-a17c9f194ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential #Initialise neural network model as a sequential network\n",
        "from keras.layers import Conv2D #Convolution operation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation#Applies activation function\n",
        "from keras.layers import Dropout#Prevents overfitting by randomly converting few outputs to zero\n",
        "from keras.layers import MaxPooling2D # Maxpooling function\n",
        "from keras.layers import Flatten # Converting 2D arrays into a 1D linear vector\n",
        "from keras.layers import Dense # Regular fully connected neural network\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2XHQzzzrRyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset_path):\n",
        "  \n",
        "  #classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprsie', 'Neutral']  #We will be dealing with seven different types of emotions.\n",
        "\n",
        "  data = []\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  labels =[]\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "      for line_no, line in enumerate(file.readlines()):\n",
        "          if 0 < line_no <= 35887:\n",
        "            curr_class, line, set_type = line.split(',')\n",
        "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)#Creating a list out of the string then converting it into a 2-Dimensional numpy array.\n",
        "            image_data =image_data.astype(np.uint8)/255.0\n",
        "            \n",
        "            if (set_type.strip() == 'PrivateTest'):\n",
        "              \n",
        "              test_data.append(image_data)\n",
        "              test_labels.append(curr_class)\n",
        "            else:\n",
        "              data.append(image_data)\n",
        "              labels.append(curr_class)\n",
        "      \n",
        "      test_data = np.expand_dims(test_data, -1)\n",
        "      test_labels = to_categorical(test_labels, num_classes = 7)\n",
        "      data = np.expand_dims(data, -1)   \n",
        "      labels = to_categorical(labels, num_classes = 7)\n",
        "    \n",
        "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFFZrnOgWOII",
        "colab_type": "text"
      },
      "source": [
        "## Load the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpdOghEhxmsd",
        "colab_type": "code",
        "outputId": "140252f9-e6cb-4324-c3bc-e9ca7a13a43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "dataset_path = \"/content/gdrive/My Drive/Colab Notebooks/fer2/fer2013.csv\" \n",
        "train_data, train_labels, test_data, test_labels = load_data(dataset_path)\n",
        "#train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = test_size,random_state = seed)\n",
        "\n",
        "print(\"Number of images in Training set:\", len(train_data))\n",
        "print(\"Number of images in Test set:\", len(test_data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in Training set: 32298\n",
            "Number of images in Test set: 3589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RT67pZKE-Sjq"
      },
      "source": [
        "##  Define and Deploy the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d004c8c3-e701-48c3-cf6b-48d7212fcaa9",
        "id": "lSek0-il-PX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "adam = optimizers.Adam(lr = learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
        "checkpointer = ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model_info=model.fit(\n",
        "                      train_data,\n",
        "                      train_labels,\n",
        "                      epochs = epochs,\n",
        "                      batch_size = batch_size,\n",
        "                      validation_split = 0.2,\n",
        "                      shuffle = True,\n",
        "                      callbacks=[lr_reducer, checkpointer, early_stopper]\n",
        "                      )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 9,014,727\n",
            "Trainable params: 9,009,223\n",
            "Non-trainable params: 5,504\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 25838 samples, validate on 6460 samples\n",
            "Epoch 1/100\n",
            "25838/25838 [==============================] - 33s 1ms/step - loss: 2.0838 - accuracy: 0.2026 - val_loss: 1.8632 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.86322, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 2/100\n",
            "  192/25838 [..............................] - ETA: 22s - loss: 1.8671 - accuracy: 0.1979"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25838/25838 [==============================] - 24s 937us/step - loss: 1.8648 - accuracy: 0.2342 - val_loss: 1.8347 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.86322 to 1.83472, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 3/100\n",
            "25838/25838 [==============================] - 24s 944us/step - loss: 1.8413 - accuracy: 0.2463 - val_loss: 1.8320 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.83472 to 1.83196, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 4/100\n",
            "25838/25838 [==============================] - 24s 936us/step - loss: 1.8332 - accuracy: 0.2489 - val_loss: 1.8210 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.83196 to 1.82096, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 5/100\n",
            "25838/25838 [==============================] - 24s 935us/step - loss: 1.8210 - accuracy: 0.2511 - val_loss: 1.8122 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.82096 to 1.81225, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 6/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 1.8166 - accuracy: 0.2514 - val_loss: 1.8055 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.81225 to 1.80554, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 7/100\n",
            "25838/25838 [==============================] - 24s 933us/step - loss: 1.8076 - accuracy: 0.2544 - val_loss: 1.8290 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.80554\n",
            "Epoch 8/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 1.7945 - accuracy: 0.2590 - val_loss: 1.8286 - val_accuracy: 0.2488\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.80554\n",
            "Epoch 9/100\n",
            "25838/25838 [==============================] - 24s 926us/step - loss: 1.7588 - accuracy: 0.2814 - val_loss: 1.8451 - val_accuracy: 0.1929\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.80554\n",
            "Epoch 10/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 1.6855 - accuracy: 0.3083 - val_loss: 1.6707 - val_accuracy: 0.2963\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.80554 to 1.67072, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 11/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 1.6289 - accuracy: 0.3243 - val_loss: 1.7320 - val_accuracy: 0.2570\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.67072\n",
            "Epoch 12/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 1.5738 - accuracy: 0.3608 - val_loss: 1.4708 - val_accuracy: 0.4002\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.67072 to 1.47084, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 13/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 1.5355 - accuracy: 0.3873 - val_loss: 1.4482 - val_accuracy: 0.4197\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.47084 to 1.44820, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 14/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 1.5042 - accuracy: 0.3995 - val_loss: 1.4254 - val_accuracy: 0.4124\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.44820 to 1.42538, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 15/100\n",
            "25838/25838 [==============================] - 24s 938us/step - loss: 1.4684 - accuracy: 0.4132 - val_loss: 1.4504 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.42538\n",
            "Epoch 16/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 1.4451 - accuracy: 0.4212 - val_loss: 1.3615 - val_accuracy: 0.4455\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.42538 to 1.36148, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 17/100\n",
            "25838/25838 [==============================] - 24s 937us/step - loss: 1.4228 - accuracy: 0.4333 - val_loss: 1.4665 - val_accuracy: 0.3885\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.36148\n",
            "Epoch 18/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 1.3962 - accuracy: 0.4411 - val_loss: 1.4562 - val_accuracy: 0.3884\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.36148\n",
            "Epoch 19/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 1.3782 - accuracy: 0.4428 - val_loss: 1.4066 - val_accuracy: 0.4296\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.36148\n",
            "Epoch 20/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 1.3354 - accuracy: 0.4620 - val_loss: 1.3024 - val_accuracy: 0.4664\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.36148 to 1.30240, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 21/100\n",
            "25838/25838 [==============================] - 24s 938us/step - loss: 1.3121 - accuracy: 0.4658 - val_loss: 1.2766 - val_accuracy: 0.4741\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.30240 to 1.27663, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 22/100\n",
            "25838/25838 [==============================] - 24s 941us/step - loss: 1.2915 - accuracy: 0.4757 - val_loss: 1.2827 - val_accuracy: 0.4859\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.27663\n",
            "Epoch 23/100\n",
            "25838/25838 [==============================] - 24s 930us/step - loss: 1.2856 - accuracy: 0.4845 - val_loss: 1.2689 - val_accuracy: 0.4760\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.27663 to 1.26894, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 24/100\n",
            "25838/25838 [==============================] - 24s 939us/step - loss: 1.2531 - accuracy: 0.5001 - val_loss: 1.2328 - val_accuracy: 0.5152\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.26894 to 1.23284, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 25/100\n",
            "25838/25838 [==============================] - 24s 937us/step - loss: 1.2362 - accuracy: 0.5132 - val_loss: 1.2459 - val_accuracy: 0.5155\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.23284\n",
            "Epoch 26/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 1.2130 - accuracy: 0.5271 - val_loss: 1.2058 - val_accuracy: 0.5450\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.23284 to 1.20583, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 27/100\n",
            "25838/25838 [==============================] - 24s 936us/step - loss: 1.2043 - accuracy: 0.5365 - val_loss: 1.1995 - val_accuracy: 0.5424\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.20583 to 1.19946, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 28/100\n",
            "25838/25838 [==============================] - 24s 943us/step - loss: 1.1759 - accuracy: 0.5461 - val_loss: 1.1980 - val_accuracy: 0.5483\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.19946 to 1.19805, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 29/100\n",
            "25838/25838 [==============================] - 24s 940us/step - loss: 1.1530 - accuracy: 0.5559 - val_loss: 1.1883 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.19805 to 1.18830, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 30/100\n",
            "25838/25838 [==============================] - 24s 939us/step - loss: 1.1389 - accuracy: 0.5643 - val_loss: 1.1676 - val_accuracy: 0.5670\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.18830 to 1.16762, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 31/100\n",
            "25838/25838 [==============================] - 24s 938us/step - loss: 1.1148 - accuracy: 0.5730 - val_loss: 1.1826 - val_accuracy: 0.5502\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.16762\n",
            "Epoch 32/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 1.1004 - accuracy: 0.5788 - val_loss: 1.1572 - val_accuracy: 0.5667\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.16762 to 1.15722, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 33/100\n",
            "25838/25838 [==============================] - 24s 940us/step - loss: 1.0828 - accuracy: 0.5853 - val_loss: 1.1395 - val_accuracy: 0.5786\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.15722 to 1.13953, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 34/100\n",
            "25838/25838 [==============================] - 24s 940us/step - loss: 1.0633 - accuracy: 0.5959 - val_loss: 1.1436 - val_accuracy: 0.5825\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.13953\n",
            "Epoch 35/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 1.0485 - accuracy: 0.6011 - val_loss: 1.1443 - val_accuracy: 0.5850\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.13953\n",
            "Epoch 36/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 1.0269 - accuracy: 0.6127 - val_loss: 1.1935 - val_accuracy: 0.5670\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.13953\n",
            "Epoch 37/100\n",
            "25838/25838 [==============================] - 24s 933us/step - loss: 0.9768 - accuracy: 0.6291 - val_loss: 1.1821 - val_accuracy: 0.5830\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.13953\n",
            "Epoch 38/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.9594 - accuracy: 0.6409 - val_loss: 1.1786 - val_accuracy: 0.5940\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.13953\n",
            "Epoch 39/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 0.9383 - accuracy: 0.6487 - val_loss: 1.1353 - val_accuracy: 0.5964\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.13953 to 1.13534, saving model to /content/gdrive/My Drive/Colab Notebooks/fer2/weights.hd5\n",
            "Epoch 40/100\n",
            "25838/25838 [==============================] - 24s 942us/step - loss: 0.9246 - accuracy: 0.6534 - val_loss: 1.1440 - val_accuracy: 0.6040\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.13534\n",
            "Epoch 41/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 0.9122 - accuracy: 0.6623 - val_loss: 1.1648 - val_accuracy: 0.5974\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.13534\n",
            "Epoch 42/100\n",
            "25838/25838 [==============================] - 24s 929us/step - loss: 0.8905 - accuracy: 0.6684 - val_loss: 1.1791 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.13534\n",
            "Epoch 43/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.8645 - accuracy: 0.6789 - val_loss: 1.1659 - val_accuracy: 0.6071\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.13534\n",
            "Epoch 44/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 0.8395 - accuracy: 0.6878 - val_loss: 1.1807 - val_accuracy: 0.6093\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.13534\n",
            "Epoch 45/100\n",
            "25838/25838 [==============================] - 24s 930us/step - loss: 0.8415 - accuracy: 0.6867 - val_loss: 1.1814 - val_accuracy: 0.6098\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.13534\n",
            "Epoch 46/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 0.8160 - accuracy: 0.6945 - val_loss: 1.2073 - val_accuracy: 0.6153\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.13534\n",
            "Epoch 47/100\n",
            "25838/25838 [==============================] - 24s 929us/step - loss: 0.8105 - accuracy: 0.7018 - val_loss: 1.1998 - val_accuracy: 0.6110\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.13534\n",
            "Epoch 48/100\n",
            "25838/25838 [==============================] - 24s 926us/step - loss: 0.8004 - accuracy: 0.7025 - val_loss: 1.2095 - val_accuracy: 0.6110\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.13534\n",
            "Epoch 49/100\n",
            "25838/25838 [==============================] - 24s 929us/step - loss: 0.7911 - accuracy: 0.7059 - val_loss: 1.2069 - val_accuracy: 0.6147\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.13534\n",
            "Epoch 50/100\n",
            "25838/25838 [==============================] - 24s 930us/step - loss: 0.7946 - accuracy: 0.7065 - val_loss: 1.2147 - val_accuracy: 0.6173\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.13534\n",
            "Epoch 51/100\n",
            "25838/25838 [==============================] - 24s 926us/step - loss: 0.7897 - accuracy: 0.7066 - val_loss: 1.2224 - val_accuracy: 0.6153\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.13534\n",
            "Epoch 52/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 0.7816 - accuracy: 0.7124 - val_loss: 1.2170 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.13534\n",
            "Epoch 53/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.7789 - accuracy: 0.7129 - val_loss: 1.2287 - val_accuracy: 0.6173\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.13534\n",
            "Epoch 54/100\n",
            "25838/25838 [==============================] - 24s 930us/step - loss: 0.7792 - accuracy: 0.7098 - val_loss: 1.2246 - val_accuracy: 0.6170\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.13534\n",
            "Epoch 55/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 0.7752 - accuracy: 0.7119 - val_loss: 1.2279 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.13534\n",
            "Epoch 56/100\n",
            "25838/25838 [==============================] - 24s 929us/step - loss: 0.7753 - accuracy: 0.7150 - val_loss: 1.2283 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.13534\n",
            "Epoch 57/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 0.7716 - accuracy: 0.7153 - val_loss: 1.2313 - val_accuracy: 0.6178\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.13534\n",
            "Epoch 58/100\n",
            "25838/25838 [==============================] - 24s 930us/step - loss: 0.7711 - accuracy: 0.7143 - val_loss: 1.2312 - val_accuracy: 0.6170\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.13534\n",
            "Epoch 59/100\n",
            "25838/25838 [==============================] - 24s 929us/step - loss: 0.7798 - accuracy: 0.7088 - val_loss: 1.2301 - val_accuracy: 0.6169\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.13534\n",
            "Epoch 60/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.7733 - accuracy: 0.7122 - val_loss: 1.2317 - val_accuracy: 0.6159\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.13534\n",
            "Epoch 61/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 0.7677 - accuracy: 0.7162 - val_loss: 1.2358 - val_accuracy: 0.6153\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.13534\n",
            "Epoch 62/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 0.7713 - accuracy: 0.7148 - val_loss: 1.2319 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.13534\n",
            "Epoch 63/100\n",
            "25838/25838 [==============================] - 24s 929us/step - loss: 0.7700 - accuracy: 0.7167 - val_loss: 1.2324 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.13534\n",
            "Epoch 64/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 0.7664 - accuracy: 0.7161 - val_loss: 1.2335 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.13534\n",
            "Epoch 65/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 0.7749 - accuracy: 0.7136 - val_loss: 1.2320 - val_accuracy: 0.6150\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.13534\n",
            "Epoch 66/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.7683 - accuracy: 0.7122 - val_loss: 1.2343 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.13534\n",
            "Epoch 67/100\n",
            "25838/25838 [==============================] - 24s 924us/step - loss: 0.7755 - accuracy: 0.7168 - val_loss: 1.2332 - val_accuracy: 0.6161\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.13534\n",
            "Epoch 68/100\n",
            "25838/25838 [==============================] - 24s 917us/step - loss: 0.7677 - accuracy: 0.7117 - val_loss: 1.2328 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.13534\n",
            "Epoch 69/100\n",
            "25838/25838 [==============================] - 24s 919us/step - loss: 0.7619 - accuracy: 0.7156 - val_loss: 1.2344 - val_accuracy: 0.6161\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.13534\n",
            "Epoch 70/100\n",
            "25838/25838 [==============================] - 24s 920us/step - loss: 0.7649 - accuracy: 0.7155 - val_loss: 1.2345 - val_accuracy: 0.6166\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.13534\n",
            "Epoch 71/100\n",
            "25838/25838 [==============================] - 24s 924us/step - loss: 0.7656 - accuracy: 0.7139 - val_loss: 1.2341 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.13534\n",
            "Epoch 72/100\n",
            "25838/25838 [==============================] - 24s 933us/step - loss: 0.7696 - accuracy: 0.7146 - val_loss: 1.2339 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.13534\n",
            "Epoch 73/100\n",
            "25838/25838 [==============================] - 24s 935us/step - loss: 0.7637 - accuracy: 0.7177 - val_loss: 1.2330 - val_accuracy: 0.6170\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.13534\n",
            "Epoch 74/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.7752 - accuracy: 0.7154 - val_loss: 1.2346 - val_accuracy: 0.6161\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.13534\n",
            "Epoch 75/100\n",
            "25838/25838 [==============================] - 24s 935us/step - loss: 0.7687 - accuracy: 0.7148 - val_loss: 1.2346 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.13534\n",
            "Epoch 76/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.7734 - accuracy: 0.7157 - val_loss: 1.2343 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.13534\n",
            "Epoch 77/100\n",
            "25838/25838 [==============================] - 24s 930us/step - loss: 0.7743 - accuracy: 0.7143 - val_loss: 1.2334 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.13534\n",
            "Epoch 78/100\n",
            "25838/25838 [==============================] - 24s 937us/step - loss: 0.7681 - accuracy: 0.7131 - val_loss: 1.2329 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.13534\n",
            "Epoch 79/100\n",
            "25838/25838 [==============================] - 24s 941us/step - loss: 0.7727 - accuracy: 0.7146 - val_loss: 1.2347 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.13534\n",
            "Epoch 80/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 0.7773 - accuracy: 0.7124 - val_loss: 1.2343 - val_accuracy: 0.6161\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.13534\n",
            "Epoch 81/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.7708 - accuracy: 0.7129 - val_loss: 1.2346 - val_accuracy: 0.6166\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.13534\n",
            "Epoch 82/100\n",
            "25838/25838 [==============================] - 24s 932us/step - loss: 0.7706 - accuracy: 0.7131 - val_loss: 1.2347 - val_accuracy: 0.6166\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.13534\n",
            "Epoch 83/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 0.7691 - accuracy: 0.7134 - val_loss: 1.2359 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.13534\n",
            "Epoch 84/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 0.7662 - accuracy: 0.7143 - val_loss: 1.2346 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.13534\n",
            "Epoch 85/100\n",
            "25838/25838 [==============================] - 24s 933us/step - loss: 0.7666 - accuracy: 0.7137 - val_loss: 1.2324 - val_accuracy: 0.6173\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.13534\n",
            "Epoch 86/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 0.7729 - accuracy: 0.7133 - val_loss: 1.2341 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.13534\n",
            "Epoch 87/100\n",
            "25838/25838 [==============================] - 24s 934us/step - loss: 0.7703 - accuracy: 0.7141 - val_loss: 1.2332 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.13534\n",
            "Epoch 88/100\n",
            "25838/25838 [==============================] - 24s 933us/step - loss: 0.7694 - accuracy: 0.7110 - val_loss: 1.2336 - val_accuracy: 0.6170\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 1.13534\n",
            "Epoch 89/100\n",
            "25838/25838 [==============================] - 24s 929us/step - loss: 0.7706 - accuracy: 0.7129 - val_loss: 1.2347 - val_accuracy: 0.6169\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.13534\n",
            "Epoch 90/100\n",
            "25838/25838 [==============================] - 24s 930us/step - loss: 0.7698 - accuracy: 0.7149 - val_loss: 1.2319 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 1.13534\n",
            "Epoch 91/100\n",
            "25838/25838 [==============================] - 24s 928us/step - loss: 0.7723 - accuracy: 0.7133 - val_loss: 1.2349 - val_accuracy: 0.6159\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.13534\n",
            "Epoch 92/100\n",
            "25838/25838 [==============================] - 24s 933us/step - loss: 0.7664 - accuracy: 0.7130 - val_loss: 1.2350 - val_accuracy: 0.6167\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.13534\n",
            "Epoch 93/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 0.7785 - accuracy: 0.7114 - val_loss: 1.2321 - val_accuracy: 0.6170\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.13534\n",
            "Epoch 94/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 0.7730 - accuracy: 0.7136 - val_loss: 1.2343 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.13534\n",
            "Epoch 95/100\n",
            "25838/25838 [==============================] - 24s 926us/step - loss: 0.7685 - accuracy: 0.7135 - val_loss: 1.2346 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.13534\n",
            "Epoch 96/100\n",
            "25838/25838 [==============================] - 24s 925us/step - loss: 0.7663 - accuracy: 0.7126 - val_loss: 1.2339 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.13534\n",
            "Epoch 97/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 0.7738 - accuracy: 0.7119 - val_loss: 1.2332 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.13534\n",
            "Epoch 98/100\n",
            "25838/25838 [==============================] - 24s 927us/step - loss: 0.7695 - accuracy: 0.7125 - val_loss: 1.2355 - val_accuracy: 0.6170\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.13534\n",
            "Epoch 99/100\n",
            "25838/25838 [==============================] - 24s 926us/step - loss: 0.7746 - accuracy: 0.7108 - val_loss: 1.2351 - val_accuracy: 0.6161\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.13534\n",
            "Epoch 100/100\n",
            "25838/25838 [==============================] - 24s 931us/step - loss: 0.7738 - accuracy: 0.7142 - val_loss: 1.2342 - val_accuracy: 0.6153\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 1.13534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK0kKSWGMM8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "51e1a68b-e0b7-4e4f-ab5c-42dcbc17fb22"
      },
      "source": [
        "print(model_info.history.keys())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model_info.history['accuracy'])\n",
        "plt.plot(model_info.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HmUdaw6Vjaj",
        "colab_type": "code",
        "outputId": "a2d1ec38-36b0-4701-e2a0-c4fc192424bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "print(model_info.history.keys())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model_info.history['loss'])\n",
        "plt.plot(model_info.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzhQw9NOWjl3",
        "colab_type": "code",
        "outputId": "27b83aa0-715b-4104-a82d-5f42fc33cbc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "predicted_test_labels = np.argmax(model.predict(test_data), axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "print (\"Accuracy score = \", accuracy_score(test_labels, predicted_test_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score =  0.6029534689328504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGsta6kKHr82",
        "colab_type": "text"
      },
      "source": [
        "###  Save the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiMswpPsr4KK",
        "colab_type": "code",
        "outputId": "a09815e9-0285-4d87-bca0-8e9a7825373e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/gdrive/My Drive/Colab Notebooks/fer2/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/gdrive/My Drive/Colab Notebooks/fer2/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkGaDW4KagX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}