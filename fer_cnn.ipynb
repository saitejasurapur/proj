{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fer cnn",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxQDaDGyjcYP",
        "colab_type": "text"
      },
      "source": [
        "# Facial Emotion Recognition \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQpjWg4Ld6m",
        "colab_type": "text"
      },
      "source": [
        "##  Connect google Drive.\n",
        "\n",
        "FER2013 dataset.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyTEuhg7fR9P",
        "colab_type": "code",
        "outputId": "03228636-deba-4b24-c35b-1f28fb5a028e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRPQRtXGmm2W",
        "colab_type": "code",
        "outputId": "864d9ff4-f785-428a-9d3c-94bc2c844c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential #Initialise neural network model as a sequential network\n",
        "from keras.layers import Conv2D #Convolution operation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation#Applies activation function\n",
        "from keras.layers import Dropout#Prevents overfitting by randomly converting few outputs to zero\n",
        "from keras.layers import MaxPooling2D # Maxpooling function\n",
        "from keras.layers import Flatten # Converting 2D arrays into a 1D linear vector\n",
        "from keras.layers import Dense # Regular fully connected neural network\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2XHQzzzrRyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset_path):\n",
        "  \n",
        "  #classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprsie', 'Neutral']  #We will be dealing with seven different types of emotions.\n",
        "\n",
        "  data = []\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  labels =[]\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "      for line_no, line in enumerate(file.readlines()):\n",
        "          if 0 < line_no <= 35887:\n",
        "            curr_class, line, set_type = line.split(',')\n",
        "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)#Creating a list out of the string then converting it into a 2-Dimensional numpy array.\n",
        "            image_data =image_data.astype(np.uint8)/255.0\n",
        "            \n",
        "            if (set_type.strip() == 'PrivateTest'):\n",
        "              \n",
        "              test_data.append(image_data)\n",
        "              test_labels.append(curr_class)\n",
        "            else:\n",
        "              data.append(image_data)\n",
        "              labels.append(curr_class)\n",
        "      \n",
        "      test_data = np.expand_dims(test_data, -1)\n",
        "      test_labels = to_categorical(test_labels, num_classes = 7)\n",
        "      data = np.expand_dims(data, -1)   \n",
        "      labels = to_categorical(labels, num_classes = 7)\n",
        "    \n",
        "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFFZrnOgWOII",
        "colab_type": "text"
      },
      "source": [
        "## Load the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpdOghEhxmsd",
        "colab_type": "code",
        "outputId": "6e59a14f-5efa-403d-f226-9111609fc791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dataset_path = \"/content/gdrive/My Drive/Colab Notebooks/fer/fer2013.csv\" \n",
        "train_data, train_labels, test_data, test_labels = load_data(dataset_path)\n",
        "#train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = test_size,random_state = seed)\n",
        "\n",
        "print(\"Number of images in Training set:\", len(train_data))\n",
        "print(\"Number of images in Test set:\", len(test_data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in Training set: 32298\n",
            "Number of images in Test set: 3589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RT67pZKE-Sjq"
      },
      "source": [
        "##  Define and Deploy the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "74b97113-5005-41f3-8e8c-ff209cc7d15a",
        "id": "lSek0-il-PX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "adam = optimizers.Adam(lr = learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
        "checkpointer = ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data,\n",
        "          train_labels,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.2,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, checkpointer, early_stopper]\n",
        "          )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 9,014,727\n",
            "Trainable params: 9,009,223\n",
            "Non-trainable params: 5,504\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 25838 samples, validate on 6460 samples\n",
            "Epoch 1/100\n",
            "25838/25838 [==============================] - 35s 1ms/step - loss: 2.0996 - accuracy: 0.2027 - val_loss: 1.8682 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.86821, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 2/100\n",
            "  192/25838 [..............................] - ETA: 23s - loss: 1.9128 - accuracy: 0.2031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25838/25838 [==============================] - 26s 990us/step - loss: 1.8664 - accuracy: 0.2335 - val_loss: 1.8372 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.86821 to 1.83717, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 3/100\n",
            "25838/25838 [==============================] - 25s 987us/step - loss: 1.8386 - accuracy: 0.2458 - val_loss: 1.8238 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.83717 to 1.82375, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 4/100\n",
            "25838/25838 [==============================] - 25s 982us/step - loss: 1.8267 - accuracy: 0.2503 - val_loss: 1.8245 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.82375\n",
            "Epoch 5/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 1.8231 - accuracy: 0.2497 - val_loss: 1.8168 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.82375 to 1.81681, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 6/100\n",
            "25838/25838 [==============================] - 25s 982us/step - loss: 1.8191 - accuracy: 0.2514 - val_loss: 1.8116 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.81681 to 1.81164, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 7/100\n",
            "25838/25838 [==============================] - 25s 977us/step - loss: 1.8124 - accuracy: 0.2517 - val_loss: 1.7976 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.81164 to 1.79760, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 8/100\n",
            "25838/25838 [==============================] - 25s 974us/step - loss: 1.8020 - accuracy: 0.2523 - val_loss: 1.8346 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.79760\n",
            "Epoch 9/100\n",
            "25838/25838 [==============================] - 25s 974us/step - loss: 1.7913 - accuracy: 0.2614 - val_loss: 1.8086 - val_accuracy: 0.2582\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.79760\n",
            "Epoch 10/100\n",
            "25838/25838 [==============================] - 25s 975us/step - loss: 1.7706 - accuracy: 0.2754 - val_loss: 1.9784 - val_accuracy: 0.2489\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.79760\n",
            "Epoch 11/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 1.7286 - accuracy: 0.2931 - val_loss: 1.7129 - val_accuracy: 0.2991\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.79760 to 1.71292, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 12/100\n",
            "25838/25838 [==============================] - 25s 985us/step - loss: 1.7052 - accuracy: 0.3037 - val_loss: 1.6705 - val_accuracy: 0.3152\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.71292 to 1.67051, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 13/100\n",
            "25838/25838 [==============================] - 25s 975us/step - loss: 1.6517 - accuracy: 0.3181 - val_loss: 1.6008 - val_accuracy: 0.3488\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.67051 to 1.60079, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 14/100\n",
            "25838/25838 [==============================] - 25s 980us/step - loss: 1.5947 - accuracy: 0.3537 - val_loss: 1.7594 - val_accuracy: 0.2709\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.60079\n",
            "Epoch 15/100\n",
            "25838/25838 [==============================] - 25s 981us/step - loss: 1.5298 - accuracy: 0.3900 - val_loss: 1.5024 - val_accuracy: 0.3859\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.60079 to 1.50242, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 16/100\n",
            "25838/25838 [==============================] - 25s 980us/step - loss: 1.4901 - accuracy: 0.4100 - val_loss: 1.4335 - val_accuracy: 0.4272\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.50242 to 1.43348, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 17/100\n",
            "25838/25838 [==============================] - 25s 975us/step - loss: 1.4557 - accuracy: 0.4193 - val_loss: 1.4247 - val_accuracy: 0.4362\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.43348 to 1.42470, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 18/100\n",
            "25838/25838 [==============================] - 25s 980us/step - loss: 1.4380 - accuracy: 0.4262 - val_loss: 1.3896 - val_accuracy: 0.4354\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.42470 to 1.38962, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 19/100\n",
            "25838/25838 [==============================] - 25s 978us/step - loss: 1.4121 - accuracy: 0.4311 - val_loss: 1.4071 - val_accuracy: 0.4276\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.38962\n",
            "Epoch 20/100\n",
            "25838/25838 [==============================] - 25s 973us/step - loss: 1.3841 - accuracy: 0.4384 - val_loss: 1.3910 - val_accuracy: 0.4293\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.38962\n",
            "Epoch 21/100\n",
            "25838/25838 [==============================] - 25s 968us/step - loss: 1.3729 - accuracy: 0.4430 - val_loss: 1.3579 - val_accuracy: 0.4331\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.38962 to 1.35790, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 22/100\n",
            "25838/25838 [==============================] - 25s 974us/step - loss: 1.3536 - accuracy: 0.4494 - val_loss: 1.3442 - val_accuracy: 0.4429\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.35790 to 1.34422, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 23/100\n",
            "25838/25838 [==============================] - 25s 986us/step - loss: 1.3417 - accuracy: 0.4530 - val_loss: 1.3421 - val_accuracy: 0.4559\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.34422 to 1.34212, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 24/100\n",
            "25838/25838 [==============================] - 26s 994us/step - loss: 1.3294 - accuracy: 0.4583 - val_loss: 1.3578 - val_accuracy: 0.4466\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.34212\n",
            "Epoch 25/100\n",
            "25838/25838 [==============================] - 25s 984us/step - loss: 1.3173 - accuracy: 0.4585 - val_loss: 1.3165 - val_accuracy: 0.4667\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.34212 to 1.31654, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 26/100\n",
            "25838/25838 [==============================] - 26s 989us/step - loss: 1.2923 - accuracy: 0.4725 - val_loss: 1.2955 - val_accuracy: 0.4817\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.31654 to 1.29552, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 27/100\n",
            "25838/25838 [==============================] - 26s 990us/step - loss: 1.2768 - accuracy: 0.4877 - val_loss: 1.2782 - val_accuracy: 0.5057\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.29552 to 1.27825, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 28/100\n",
            "25838/25838 [==============================] - 25s 983us/step - loss: 1.2606 - accuracy: 0.5027 - val_loss: 1.2390 - val_accuracy: 0.5228\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.27825 to 1.23902, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 29/100\n",
            "25838/25838 [==============================] - 26s 989us/step - loss: 1.2388 - accuracy: 0.5167 - val_loss: 1.2364 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.23902 to 1.23638, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 30/100\n",
            "25838/25838 [==============================] - 26s 989us/step - loss: 1.2185 - accuracy: 0.5242 - val_loss: 1.2264 - val_accuracy: 0.5435\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.23638 to 1.22644, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 31/100\n",
            "25838/25838 [==============================] - 25s 985us/step - loss: 1.1894 - accuracy: 0.5354 - val_loss: 1.2125 - val_accuracy: 0.5483\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.22644 to 1.21252, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 32/100\n",
            "25838/25838 [==============================] - 25s 985us/step - loss: 1.1706 - accuracy: 0.5456 - val_loss: 1.2603 - val_accuracy: 0.5206\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.21252\n",
            "Epoch 33/100\n",
            "25838/25838 [==============================] - 25s 975us/step - loss: 1.1603 - accuracy: 0.5561 - val_loss: 1.2013 - val_accuracy: 0.5486\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.21252 to 1.20126, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 34/100\n",
            "25838/25838 [==============================] - 25s 983us/step - loss: 1.1396 - accuracy: 0.5656 - val_loss: 1.2011 - val_accuracy: 0.5568\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.20126 to 1.20108, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 35/100\n",
            "25838/25838 [==============================] - 26s 993us/step - loss: 1.1216 - accuracy: 0.5752 - val_loss: 1.1848 - val_accuracy: 0.5683\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.20108 to 1.18475, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 36/100\n",
            "25838/25838 [==============================] - 26s 991us/step - loss: 1.1032 - accuracy: 0.5788 - val_loss: 1.2070 - val_accuracy: 0.5485\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.18475\n",
            "Epoch 37/100\n",
            "25838/25838 [==============================] - 26s 993us/step - loss: 1.0712 - accuracy: 0.5936 - val_loss: 1.1858 - val_accuracy: 0.5533\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.18475\n",
            "Epoch 38/100\n",
            "25838/25838 [==============================] - 26s 988us/step - loss: 1.0618 - accuracy: 0.5987 - val_loss: 1.1683 - val_accuracy: 0.5652\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.18475 to 1.16832, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 39/100\n",
            "25838/25838 [==============================] - 26s 998us/step - loss: 1.0442 - accuracy: 0.6062 - val_loss: 1.2114 - val_accuracy: 0.5491\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.16832\n",
            "Epoch 40/100\n",
            "25838/25838 [==============================] - 25s 984us/step - loss: 1.0306 - accuracy: 0.6119 - val_loss: 1.1415 - val_accuracy: 0.5786\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.16832 to 1.14148, saving model to /content/gdrive/My Drive/Colab Notebooks/fer/weights.hd5\n",
            "Epoch 41/100\n",
            "25838/25838 [==============================] - 26s 997us/step - loss: 1.0128 - accuracy: 0.6190 - val_loss: 1.1824 - val_accuracy: 0.5622\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.14148\n",
            "Epoch 42/100\n",
            "25838/25838 [==============================] - 25s 982us/step - loss: 0.9856 - accuracy: 0.6300 - val_loss: 1.1488 - val_accuracy: 0.5927\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.14148\n",
            "Epoch 43/100\n",
            "25838/25838 [==============================] - 25s 985us/step - loss: 0.9732 - accuracy: 0.6434 - val_loss: 1.1919 - val_accuracy: 0.5807\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.14148\n",
            "Epoch 44/100\n",
            "25838/25838 [==============================] - 26s 992us/step - loss: 0.9056 - accuracy: 0.6651 - val_loss: 1.1431 - val_accuracy: 0.6146\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.14148\n",
            "Epoch 45/100\n",
            "25838/25838 [==============================] - 25s 981us/step - loss: 0.8774 - accuracy: 0.6732 - val_loss: 1.1592 - val_accuracy: 0.6163\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.14148\n",
            "Epoch 46/100\n",
            "25838/25838 [==============================] - 25s 981us/step - loss: 0.8587 - accuracy: 0.6835 - val_loss: 1.1766 - val_accuracy: 0.6119\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.14148\n",
            "Epoch 47/100\n",
            "25838/25838 [==============================] - 26s 988us/step - loss: 0.8204 - accuracy: 0.6961 - val_loss: 1.1563 - val_accuracy: 0.6150\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.14148\n",
            "Epoch 48/100\n",
            "25838/25838 [==============================] - 25s 983us/step - loss: 0.7997 - accuracy: 0.7073 - val_loss: 1.1767 - val_accuracy: 0.6159\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.14148\n",
            "Epoch 49/100\n",
            "25838/25838 [==============================] - 25s 973us/step - loss: 0.7822 - accuracy: 0.7113 - val_loss: 1.1782 - val_accuracy: 0.6156\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.14148\n",
            "Epoch 50/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.7496 - accuracy: 0.7241 - val_loss: 1.2091 - val_accuracy: 0.6241\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.14148\n",
            "Epoch 51/100\n",
            "25838/25838 [==============================] - 25s 972us/step - loss: 0.7496 - accuracy: 0.7240 - val_loss: 1.1985 - val_accuracy: 0.6228\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.14148\n",
            "Epoch 52/100\n",
            "25838/25838 [==============================] - 25s 975us/step - loss: 0.7364 - accuracy: 0.7290 - val_loss: 1.2134 - val_accuracy: 0.6231\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.14148\n",
            "Epoch 53/100\n",
            "25838/25838 [==============================] - 25s 973us/step - loss: 0.7293 - accuracy: 0.7348 - val_loss: 1.2299 - val_accuracy: 0.6237\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.14148\n",
            "Epoch 54/100\n",
            "25838/25838 [==============================] - 25s 972us/step - loss: 0.7176 - accuracy: 0.7412 - val_loss: 1.2243 - val_accuracy: 0.6206\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.14148\n",
            "Epoch 55/100\n",
            "25838/25838 [==============================] - 25s 972us/step - loss: 0.7158 - accuracy: 0.7369 - val_loss: 1.2310 - val_accuracy: 0.6223\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.14148\n",
            "Epoch 56/100\n",
            "25838/25838 [==============================] - 25s 976us/step - loss: 0.7092 - accuracy: 0.7408 - val_loss: 1.2366 - val_accuracy: 0.6209\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.14148\n",
            "Epoch 57/100\n",
            "25838/25838 [==============================] - 25s 969us/step - loss: 0.7062 - accuracy: 0.7426 - val_loss: 1.2440 - val_accuracy: 0.6228\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.14148\n",
            "Epoch 58/100\n",
            "25838/25838 [==============================] - 25s 973us/step - loss: 0.7055 - accuracy: 0.7412 - val_loss: 1.2586 - val_accuracy: 0.6260\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.14148\n",
            "Epoch 59/100\n",
            "25838/25838 [==============================] - 25s 976us/step - loss: 0.7010 - accuracy: 0.7463 - val_loss: 1.2568 - val_accuracy: 0.6235\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.14148\n",
            "Epoch 60/100\n",
            "25838/25838 [==============================] - 25s 978us/step - loss: 0.7040 - accuracy: 0.7449 - val_loss: 1.2512 - val_accuracy: 0.6254\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.14148\n",
            "Epoch 61/100\n",
            "25838/25838 [==============================] - 25s 967us/step - loss: 0.6973 - accuracy: 0.7487 - val_loss: 1.2526 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.14148\n",
            "Epoch 62/100\n",
            "25838/25838 [==============================] - 25s 973us/step - loss: 0.6961 - accuracy: 0.7471 - val_loss: 1.2582 - val_accuracy: 0.6224\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.14148\n",
            "Epoch 63/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.6961 - accuracy: 0.7461 - val_loss: 1.2534 - val_accuracy: 0.6240\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.14148\n",
            "Epoch 64/100\n",
            "25838/25838 [==============================] - 25s 969us/step - loss: 0.6971 - accuracy: 0.7470 - val_loss: 1.2577 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.14148\n",
            "Epoch 65/100\n",
            "25838/25838 [==============================] - 25s 961us/step - loss: 0.6933 - accuracy: 0.7474 - val_loss: 1.2545 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.14148\n",
            "Epoch 66/100\n",
            "25838/25838 [==============================] - 25s 970us/step - loss: 0.7000 - accuracy: 0.7445 - val_loss: 1.2608 - val_accuracy: 0.6252\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.14148\n",
            "Epoch 67/100\n",
            "25838/25838 [==============================] - 25s 981us/step - loss: 0.6909 - accuracy: 0.7479 - val_loss: 1.2607 - val_accuracy: 0.6252\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.14148\n",
            "Epoch 68/100\n",
            "25838/25838 [==============================] - 25s 975us/step - loss: 0.7034 - accuracy: 0.7451 - val_loss: 1.2605 - val_accuracy: 0.6257\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.14148\n",
            "Epoch 69/100\n",
            "25838/25838 [==============================] - 25s 978us/step - loss: 0.6907 - accuracy: 0.7494 - val_loss: 1.2584 - val_accuracy: 0.6245\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.14148\n",
            "Epoch 70/100\n",
            "25838/25838 [==============================] - 25s 972us/step - loss: 0.6957 - accuracy: 0.7453 - val_loss: 1.2612 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.14148\n",
            "Epoch 71/100\n",
            "25838/25838 [==============================] - 25s 974us/step - loss: 0.7002 - accuracy: 0.7490 - val_loss: 1.2574 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.14148\n",
            "Epoch 72/100\n",
            "25838/25838 [==============================] - 25s 970us/step - loss: 0.7039 - accuracy: 0.7451 - val_loss: 1.2611 - val_accuracy: 0.6252\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.14148\n",
            "Epoch 73/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.6924 - accuracy: 0.7488 - val_loss: 1.2624 - val_accuracy: 0.6243\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.14148\n",
            "Epoch 74/100\n",
            "25838/25838 [==============================] - 25s 964us/step - loss: 0.6930 - accuracy: 0.7465 - val_loss: 1.2592 - val_accuracy: 0.6249\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.14148\n",
            "Epoch 75/100\n",
            "25838/25838 [==============================] - 25s 970us/step - loss: 0.6956 - accuracy: 0.7470 - val_loss: 1.2626 - val_accuracy: 0.6241\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.14148\n",
            "Epoch 76/100\n",
            "25838/25838 [==============================] - 25s 966us/step - loss: 0.6952 - accuracy: 0.7467 - val_loss: 1.2618 - val_accuracy: 0.6248\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.14148\n",
            "Epoch 77/100\n",
            "25838/25838 [==============================] - 25s 967us/step - loss: 0.6879 - accuracy: 0.7443 - val_loss: 1.2609 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.14148\n",
            "Epoch 78/100\n",
            "25838/25838 [==============================] - 25s 970us/step - loss: 0.7013 - accuracy: 0.7454 - val_loss: 1.2593 - val_accuracy: 0.6243\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.14148\n",
            "Epoch 79/100\n",
            "25838/25838 [==============================] - 25s 967us/step - loss: 0.6973 - accuracy: 0.7479 - val_loss: 1.2591 - val_accuracy: 0.6238\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.14148\n",
            "Epoch 80/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.6926 - accuracy: 0.7461 - val_loss: 1.2625 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.14148\n",
            "Epoch 81/100\n",
            "25838/25838 [==============================] - 25s 970us/step - loss: 0.6947 - accuracy: 0.7477 - val_loss: 1.2607 - val_accuracy: 0.6243\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.14148\n",
            "Epoch 82/100\n",
            "25838/25838 [==============================] - 25s 968us/step - loss: 0.6909 - accuracy: 0.7467 - val_loss: 1.2608 - val_accuracy: 0.6248\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.14148\n",
            "Epoch 83/100\n",
            "25838/25838 [==============================] - 25s 969us/step - loss: 0.6963 - accuracy: 0.7460 - val_loss: 1.2588 - val_accuracy: 0.6245\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.14148\n",
            "Epoch 84/100\n",
            "25838/25838 [==============================] - 25s 968us/step - loss: 0.6947 - accuracy: 0.7462 - val_loss: 1.2603 - val_accuracy: 0.6251\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.14148\n",
            "Epoch 85/100\n",
            "25838/25838 [==============================] - 25s 978us/step - loss: 0.6957 - accuracy: 0.7464 - val_loss: 1.2621 - val_accuracy: 0.6243\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.14148\n",
            "Epoch 86/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.6912 - accuracy: 0.7448 - val_loss: 1.2604 - val_accuracy: 0.6241\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.14148\n",
            "Epoch 87/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.6947 - accuracy: 0.7468 - val_loss: 1.2618 - val_accuracy: 0.6248\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.14148\n",
            "Epoch 88/100\n",
            "25838/25838 [==============================] - 25s 968us/step - loss: 0.6924 - accuracy: 0.7457 - val_loss: 1.2609 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 1.14148\n",
            "Epoch 89/100\n",
            "25838/25838 [==============================] - 25s 970us/step - loss: 0.6902 - accuracy: 0.7487 - val_loss: 1.2615 - val_accuracy: 0.6248\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.14148\n",
            "Epoch 90/100\n",
            "25838/25838 [==============================] - 25s 974us/step - loss: 0.6967 - accuracy: 0.7443 - val_loss: 1.2620 - val_accuracy: 0.6249\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 1.14148\n",
            "Epoch 91/100\n",
            "25838/25838 [==============================] - 25s 972us/step - loss: 0.6964 - accuracy: 0.7416 - val_loss: 1.2614 - val_accuracy: 0.6251\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.14148\n",
            "Epoch 92/100\n",
            "25838/25838 [==============================] - 25s 967us/step - loss: 0.6938 - accuracy: 0.7468 - val_loss: 1.2575 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.14148\n",
            "Epoch 93/100\n",
            "25838/25838 [==============================] - 25s 965us/step - loss: 0.6918 - accuracy: 0.7489 - val_loss: 1.2643 - val_accuracy: 0.6249\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.14148\n",
            "Epoch 94/100\n",
            "25838/25838 [==============================] - 25s 966us/step - loss: 0.6929 - accuracy: 0.7506 - val_loss: 1.2625 - val_accuracy: 0.6245\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.14148\n",
            "Epoch 95/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.6907 - accuracy: 0.7455 - val_loss: 1.2598 - val_accuracy: 0.6245\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.14148\n",
            "Epoch 96/100\n",
            "25838/25838 [==============================] - 25s 971us/step - loss: 0.6906 - accuracy: 0.7479 - val_loss: 1.2616 - val_accuracy: 0.6243\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.14148\n",
            "Epoch 97/100\n",
            "25838/25838 [==============================] - 25s 974us/step - loss: 0.6994 - accuracy: 0.7446 - val_loss: 1.2630 - val_accuracy: 0.6251\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.14148\n",
            "Epoch 98/100\n",
            "25838/25838 [==============================] - 25s 973us/step - loss: 0.6959 - accuracy: 0.7492 - val_loss: 1.2601 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.14148\n",
            "Epoch 99/100\n",
            "25838/25838 [==============================] - 25s 970us/step - loss: 0.6908 - accuracy: 0.7479 - val_loss: 1.2588 - val_accuracy: 0.6245\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.14148\n",
            "Epoch 100/100\n",
            "25838/25838 [==============================] - 25s 974us/step - loss: 0.7011 - accuracy: 0.7460 - val_loss: 1.2601 - val_accuracy: 0.6240\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 1.14148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd4ec1e7b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzhQw9NOWjl3",
        "colab_type": "code",
        "outputId": "83caf726-cae9-42a3-991f-5f1610dcfce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predicted_test_labels = np.argmax(model.predict(test_data), axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "print (\"Accuracy score = \", accuracy_score(test_labels, predicted_test_labels))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score =  0.615491780440234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGsta6kKHr82",
        "colab_type": "text"
      },
      "source": [
        "###  Save the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiMswpPsr4KK",
        "colab_type": "code",
        "outputId": "962140ed-2eda-438a-fa32-49bcc852bfe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/gdrive/My Drive/Colab Notebooks/fer/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/gdrive/My Drive/Colab Notebooks/fer/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkGaDW4KagX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}